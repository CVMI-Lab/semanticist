<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Semanticist: PCA-Guided Visual Tokenization</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 40px;
            line-height: 1.6;
            max-width: 800px;
            margin: auto;
        }
        h1, h2, h3 {
            color: #333;
        }
        a {
            color: #007bff;
            text-decoration: none;
        }
        a:hover {
            text-decoration: underline;
        }
        .section {
            margin-bottom: 40px;
        }
    </style>
</head>
<body>
    <h1>"Principal Components" Enable A New Language of Images</h1>
    <h3>A New Paradigm for Compact and Interpretable Image Representations</h3>
    <p>
        <a href="#">[Read the Paper]</a> &nbsp; | &nbsp;
        <a href="https://github.com/visual-gen/semanticist">[GitHub]</a> &nbsp; | &nbsp;
        <a href="https://huggingface.co/spaces/tennant/semanticist_tokenizer">[Huggingface Tokenizer Demo]</a> &nbsp; | &nbsp;
        <a href="https://huggingface.co/spaces/tennant/Semanticist_AR">[Huggingface Generation Demo]</a>
    </p>

    <div class="section">
        <h2>Introduction & Motivation</h2>
        <p>Deep generative models have revolutionized image synthesis, but how we tokenize visual data remains an open question. 
        While classical methods like <b>Principal Component Analysis (PCA)</b> introduced compact, structured representations, modern <b>visual tokenizers</b>—from <b>VQ-VAE</b> to <b>SD-VAE</b>—often prioritize <b>reconstruction fidelity</b> at the cost of interpretability and efficiency.</p>
        <h3>The Problem</h3>
        <ul>
            <li><b>Lack of Structure:</b> Tokens are arbitrarily learned, without an ordering that prioritizes important visual features first.</li>
            <li><b>Semantic-Spectrum Coupling:</b> Tokens entangle <i>high-level semantics</i> with <i>low-level spectral details</i>, leading to inefficiencies in downstream applications.</li>
        </ul>
        <p>Can we design a <b>compact, structured tokenizer</b> that retains the benefits of PCA while leveraging modern generative techniques?</p>
    </div>

    <div class="section">
        <h2>Key Contributions (What’s New?)</h2>
        <ul>
            <li><b>📌 PCA-Guided Tokenization:</b> Introduces a <i>causal ordering</i> where earlier tokens capture the most important visual details, reducing redundancy.</li>
            <li><b>⚡ Semantic-Spectrum Decoupling:</b> Resolves the issue of semantic-spectrum coupling to ensure tokens focus on high-level semantic information.</li>
            <li><b>🌀 Diffusion-Based Decoding:</b> Uses a <i>diffusion decoder</i> for the spectral auto-regressive property to naturally separate semantic and spectral content.</li>
            <li><b>🚀 Compact & Interpretability-Friendly:</b> Enables <i>flexible token selection</i>, where fewer tokens can still yield high-quality reconstructions.</li>
        </ul>
    </div>

    <div class="section">
        <h2>Visualizing the Problem: Semantic-Spectrum Coupling</h2>
        <p>Existing methods fail to separate <b>semantics from spectral details</b>, leading to inefficiencies in token usage.</p>
        <ul>
            <li><b>🚨 Current Tokenizers:</b> More tokens simultaneously increase both <i>semantic content</i> and <i>low-level spectral details</i>, making compression inefficient.</li>
            <li><b>✅ Our Approach:</b> Tokens capture <i>semantics first</i>, ensuring a <i>coarse-to-fine</i> hierarchical structure.</li>
        </ul>
        <p><b>📊 Power Spectrum Analysis (Visual)</b><br>➡️ <img src="figs/spectral_analysis.png"></p>
        <p><b>🖼 Comparison of Reconstructions</b><br>➡️ <i>[Insert a figure comparing VQ-VAE, TiTok, and Semanticist reconstructions at different token levels]</i></p>
    </div>

    <div class="section">
        <h2>Experimental Results</h2>
        <p>We validate <b>Semanticist</b> through extensive experiments, demonstrating:</p>
        <ul>
            <li><b>🏆 State-of-the-art Reconstruction:</b> Achieves the lowest FID scores among visual tokenizers.</li>
            <li><b>🎨 Better Generative Performance:</b> Autoregressive models trained on Semanticist tokens match leading baselines with fewer tokens.</li>
            <li><b>📈 Improved Interpretability:</b> PCA-like hierarchy aligns with human perception and enhances linear probing classification accuracy.</li>
        </ul>
        <p><b>📝 Quantitative Results Table</b><br>➡️ <i>[Insert a table comparing FID, PSNR, and SSIM across methods]</i></p>
    </div>

    <div class="section">
        <h2>Broader Impact & Limitations</h2>
        <h3>Potential Applications</h3>
        <ul>
            <li><b>🔎 Image Compression:</b> More efficient representations with reduced redundancy.</li>
            <li><b>🎭 Generative Models:</b> Enhanced image synthesis with structured latents.</li>
            <li><b>📊 Data Analysis:</b> Improved interpretability and feature extraction.</li>
        </ul>
        <h3>Limitations</h3>
        <ul>
            <li><b>⏳ Inference Speed:</b> Diffusion decoding is slower than direct pixel regression.</li>
            <li><b>🤖 Alternative Architectures:</b> Flow-matching or consistency models could improve efficiency.</li>
            <li><b>📉 Adaptive Tokenization:</b> Dynamic token lengths could further optimize representation.</li>
        </ul>
        <h3>Ethical Considerations</h3>
        <p>Like all generative models, our approach could be misused for deepfake creation or content manipulation. We encourage responsible use and propose safeguards to mitigate misuse.</p>
    </div>

    <div class="section">
        <h2>Resources</h2>
        <p><a href="#">[Read the Paper]</a> &nbsp; | &nbsp; <a href="#">[GitHub Repository]</a> &nbsp; | &nbsp; <a href="#">[Colab Demo]</a></p>
        <p><b>Citation:</b> If you find our work useful, please cite us!</p>
        <p><i>[Insert BibTeX Citation Here]</i></p>
    </div>
</body>
</html>
